{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "#webscraper for user data\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "#database import\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy.types as sqltypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL is climbers in MountainProject's partner finder within 100 miles of Denver, CO\n",
    "URL = 'https://www.mountainproject.com/partner-finder/results?min-age=-&max-age=-&location=95829&distance=100&_token=iskSRmnM2pAHqwB28h4K8LU7u8gOfrsdKSHSmdtn'\n",
    "#sacramento = 'https://www.mountainproject.com/partner-finder/results?min-age=-&max-age=-&location=95829&distance=100&_token=iskSRmnM2pAHqwB28h4K8LU7u8gOfrsdKSHSmdtn'\n",
    "#st.george ='https://www.mountainproject.com/partner-finder/results?min-age=-&max-age=-&location=84735&distance=100&_token=iskSRmnM2pAHqwB28h4K8LU7u8gOfrsdKSHSmdtn'\n",
    "#saltlake= 'https://www.mountainproject.com/partner-finder/results?min-age=-&max-age=-&location=84123&distance=100&_token=iskSRmnM2pAHqwB28h4K8LU7u8gOfrsdKSHSmdtn'\n",
    "#vegas= 'https://www.mountainproject.com/partner-finder/results?min-age=-&max-age=-&location=89102&distance=100&_token=iskSRmnM2pAHqwB28h4K8LU7u8gOfrsdKSHSmdtn'\n",
    "#RedRiverGorge = 'https://www.mountainproject.com/partner-finder/results?min-age=-&max-age=-&location=40387&distance=100&_token=iskSRmnM2pAHqwB28h4K8LU7u8gOfrsdKSHSmdtn'\n",
    "#Yosimite URL =  'https://www.mountainproject.com/partner-finder/results?min-age=-&max-age=-&location=95389&distance=100&_token=iskSRmnM2pAHqwB28h4K8LU7u8gOfrsdKSHSmdtn'\n",
    "#Denver URL = 'https://www.mountainproject.com/partner-finder/results?min-age=-&max-age=-&location=80223&distance=100&_token=iskSRmnM2pAHqwB28h4K8LU7u8gOfrsdKSHSmdtn'\n",
    "page = requests.get(URL)\n",
    "soup1 = BeautifulSoup(page.content, 'html.parser')\n",
    "soup2 = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "\n",
    "user_ticklist_csv = []\n",
    "list_of_usernames= []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_user_ticklists():\n",
    "    doubled_userlinks = []\n",
    "    for link in soup2.find_all('a', attrs={'href': re.compile(\"^https://www.mountainproject.com/user/\")}):\n",
    "        doubled_userlinks.append(link.get('href'))\n",
    "    \n",
    "    user_pagelink = []\n",
    "    [user_pagelink.append(x) for x in doubled_userlinks if x not in user_pagelink]\n",
    "\n",
    "    \n",
    "    for link in user_pagelink:\n",
    "        new = link+\"/tick-export\"\n",
    "        if new not in user_ticklist_csv:\n",
    "            user_ticklist_csv.append(new)\n",
    "\n",
    "def create_df_ticklist(chunk):\n",
    "    master_ticklist_df = pd.DataFrame(columns=('Date','Route',\n",
    "    'Rating','Notes','URL','Pitches','Location','Avg Stars',\n",
    "    'Your Stars','Style','Lead Style','Route Type','Your Rating',\n",
    "    'Length','Rating Code','username', 'date_accessed'))\n",
    "    \n",
    "\n",
    "    tick_export_url = user_ticklist_csv[chunk]\n",
    "    response = requests.get(tick_export_url, stream=False)\n",
    "    data = StringIO(str(response.content, 'utf-8'))\n",
    "    \n",
    "    df = pd.read_csv(data)\n",
    "    \n",
    "    \n",
    "    url_parts = tick_export_url.split('/')\n",
    "    username = url_parts[-2].replace('-', ' ')\n",
    "    list_of_usernames.append(username)\n",
    "\n",
    "    demo_url = tick_export_url[:-12]\n",
    "    \n",
    "    response = requests.get(demo_url, stream=False)\n",
    "    \n",
    "    html_content = response.text\n",
    "    \n",
    "    soup3 = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    demographics = soup3.find('div', {'class': 'col-xs-12 text-xs-center'}).text.strip()\n",
    "    \n",
    "    try:\n",
    "        sex = re.findall('(Male|Female)', demographics)[0]\n",
    "    except IndexError:\n",
    "        sex = 'Unknown'\n",
    "    \n",
    "    try:\n",
    "        age = re.findall('\\d+', demographics)[0]\n",
    "    except IndexError:\n",
    "        age = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        df['username'] = username\n",
    "        df['date_accessed'] = datetime.now()\n",
    "        df['sex'] = sex\n",
    "        df['age'] = age\n",
    "\n",
    "    master_ticklist_df = pd.concat([master_ticklist_df, df], axis = 0, ignore_index = True)\n",
    "    \n",
    "    return master_ticklist_df  \n",
    "\n",
    "def execute_data_extraction():\n",
    "    fetch_user_ticklists()\n",
    "    \n",
    "\n",
    "    get_these_entries = 500\n",
    "    batch_size = 1\n",
    "    chunks = get_these_entries // batch_size  # Use integer division to get the number of chunks\n",
    "\n",
    "    for chunk in range(chunks):\n",
    "        max_retries = 5\n",
    "        retry_count = 0\n",
    "\n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                master_ticklist_df = create_df_ticklist(chunk)\n",
    "                break  \n",
    "            except requests.exceptions.ChunkedEncodingError:\n",
    "                print(\"Received ChunkedEncodingError. Retrying in 5 seconds...\")\n",
    "                time.sleep(5)  \n",
    "                retry_count += 1\n",
    "\n",
    "        if retry_count == max_retries:\n",
    "            print(\"Maximum number of retries reached. Check your internet connection or try again later.\")\n",
    "\n",
    "        for index, row in master_ticklist_df.iterrows():\n",
    "            try:\n",
    "                pd.to_datetime(row['Date'], format='%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                master_ticklist_df.drop(index, inplace=True)\n",
    "\n",
    "        # master_ticklist_df['sex'] = master_ticklist_df['sex'].astype('category')\n",
    "        # master_ticklist_df['age'] = master_ticklist_df['age'].astype('int64')\n",
    "        # master_ticklist_df['Rating'] = master_ticklist_df['Rating'].astype('category')\n",
    "        # master_ticklist_df['Lead Style'] = master_ticklist_df['Lead Style'].astype('category')\n",
    "        # master_ticklist_df['Route Type'] = master_ticklist_df['Route Type'].astype('category')\n",
    "        # master_ticklist_df['Your Rating'] = master_ticklist_df['Your Rating'].astype('category')\n",
    "        # master_ticklist_df['Rating Code'] = master_ticklist_df['Rating Code'].astype('category')\n",
    "        # master_ticklist_df['Style'] = master_ticklist_df['Style'].astype('category')\n",
    "        # master_ticklist_df['Pitches'] = master_ticklist_df['Pitches'].astype('int64')\n",
    "        # master_ticklist_df['Your Stars'] = master_ticklist_df['Your Stars'].astype('int64')\n",
    "        \n",
    "\n",
    "    \n",
    "        sql_datatype_dictionary = {\n",
    "        'Date':sqltypes.Date(),\n",
    "        'Route':sqltypes.String(),\n",
    "        'Rating':sqltypes.String(),\n",
    "        'Notes':sqltypes.String(),\n",
    "        'URL':sqltypes.String(),\n",
    "        'Pitches':sqltypes.Integer(),\n",
    "        'Location':sqltypes.String(),\n",
    "        'Avg Stars':sqltypes.Float(),\n",
    "        'Your Stars':sqltypes.Integer(),\n",
    "        'Style':sqltypes.String(),\n",
    "        'Lead Style':sqltypes.String(),\n",
    "        'Route Type':sqltypes.String(),\n",
    "        'Your Rating':sqltypes.String(),\n",
    "        'Length':sqltypes.Integer(),\n",
    "        'Rating Code':sqltypes.String(),\n",
    "        'username':sqltypes.String(),\n",
    "        'sex':sqltypes.String(),\n",
    "        'age':sqltypes.Integer(),\n",
    "        'date_accessed':sqltypes.Date()\n",
    "        }\n",
    "    \n",
    "        engine = create_engine('postgresql://postgres:********@localhost:****/ticklists')\n",
    "\n",
    "        master_ticklist_df.to_sql('sacramento', engine, if_exists='append',dtype = sql_datatype_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_data_extraction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f7a492aa0d697cc12db94dc4980a5d586d39d5207dfbbfa1d2868066532a75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
